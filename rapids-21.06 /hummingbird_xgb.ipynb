{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497b428d-df12-4ccd-9773-504d9e908f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from hummingbird.ml import convert, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e547dc2-5583-4500-a47e-46d22d6dedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec22da28-4bc8-49d9-bc1e-c9f5da7a5bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some random data for binary classification\n",
    "num_classes = 2\n",
    "X = np.random.rand(100000, 28)\n",
    "y = np.random.randint(num_classes, size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e959f7-4ff5-4fbd-aafe-855ca33df422",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73aeeb79-98d6-463d-ad21-82b76c3541f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"humming_bird\"+\"-\"+str(estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102da9b3-c904-4a8d-975a-d6bf8981e165",
   "metadata": {},
   "source": [
    "## Train the xgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "748e589d-d072-46c8-89f8-0af0aad60938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model (XGBoost in this case).\n",
    "model = xgb.XGBRegressor(n_estimators=estimators, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e4d2c3a-93ac-473a-b361-a1a48529c845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=10,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=25, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8eea3e6-e5af-42ab-8a20-f9937e5b2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e75f9-e4d4-419f-bc32-b22bb7e7c1dc",
   "metadata": {},
   "source": [
    "## Load the xgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48131c94-73de-49e4-837d-1b5d65162150",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d275bfc7-3d82-467c-8976-e735b98b5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "300982b4-fa2a-4169-a2c4-ba031aea4c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67077154, 0.42272907, 0.6180591 , ..., 0.45412898, 0.48937115,\n",
       "       0.51849025], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c8f43c-ed12-487b-9777-c91c5c36a940",
   "metadata": {},
   "source": [
    "## Humming Bird converting to Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7e8284d-ad6e-4138-a1bf-9131edfe1d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 385.48 MiB, increment: 8.27 MiB\n",
      "CPU times: user 1.82 s, sys: 12.1 ms, total: 1.83 s\n",
      "Wall time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# Use Hummingbird to convert the model to PyTorch\n",
    "# Note that XGBRegressor requires us to pass it some sample data.\n",
    "hb_model = convert(model_loaded, 'torch', X[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d4580e-d987-41ea-99b5-80629f2ed65f",
   "metadata": {},
   "source": [
    "#### Humming Bird on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c87ad58-b41b-4399-852d-f2133b7d3b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 ms ± 68.4 µs per loop (mean ± std. dev. of 3 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3\n",
    "\n",
    "# Run Hummingbird on CPU - By default CPU execution is used in Hummingbird.\n",
    "hb_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be30809-ecfb-47d7-9d58-ad6091098cd6",
   "metadata": {},
   "source": [
    "#### Humming Bird on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d595e37-f14f-4094-842a-08ca3cef8cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3062.85 MiB, increment: 2422.35 MiB\n",
      "CPU times: user 2.21 s, sys: 1.19 s, total: 3.41 s\n",
      "Wall time: 3.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "# Run Hummingbird on GPU (Note that you must have a GPU-enabled machine).\n",
    "hb_model.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57c8af05-b3b7-47cd-8dc4-a9c99f71de61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.5 ms ± 1.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "hb_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60264d7b-750f-4d20-9b05-ac804d3afbbc",
   "metadata": {},
   "source": [
    "## Predict using FIL on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "281760d0-590e-4e33-bc82-52259596846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml import ForestInference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a38e9-d908-4f4a-b571-81b4f9f42e6f",
   "metadata": {},
   "source": [
    "#### Using Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83c2aee8-5c1f-446b-ac47-7bdae37541fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4797.70 MiB, increment: 1561.10 MiB\n",
      "CPU times: user 1.19 s, sys: 569 ms, total: 1.76 s\n",
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "fil_model_naive = ForestInference.load(\n",
    "    filename=model_path,\n",
    "    algo='NAIVE',\n",
    "    output_class=True,\n",
    "    threshold=0.50,\n",
    "    model_type='xgboost'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75f38b85-e8bd-484a-b976-62d1746669ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8 ms ± 38.4 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3\n",
    "# perform prediction on the model loaded from path\n",
    "fil_preds_naive = fil_model_naive.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e66e5d6-de8a-4164-a368-37079e5ea880",
   "metadata": {},
   "source": [
    "#### Using Tree Reorg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f10ea74d-4ca5-44d3-8512-370055a30790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4825.12 MiB, increment: 0.12 MiB\n",
      "CPU times: user 199 ms, sys: 137 ms, total: 336 ms\n",
      "Wall time: 404 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "fil_model_btr = ForestInference.load(\n",
    "    filename=model_path,\n",
    "    algo='BATCH_TREE_REORG',\n",
    "    output_class=True,\n",
    "    threshold=0.50,\n",
    "    model_type='xgboost'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90a74c85-50ee-4375-acc0-2e2fac5c49e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.9 ms ± 39.8 µs per loop (mean ± std. dev. of 3 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3\n",
    "# perform prediction on the model loaded from path\n",
    "fil_preds_btr = fil_model_btr.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
