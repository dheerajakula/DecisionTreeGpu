{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Inference Library (FIL)\n",
    "The forest inference library is used to load saved forest models of xgboost, lightgbm and perform inference on them. It can be used to perform both classification and regression. In this notebook, we'll begin by fitting a model with XGBoost and saving it. We'll then load the saved model into FIL and use it to infer on new data.\n",
    "\n",
    "FIL works in the same way with lightgbm model as well.\n",
    "\n",
    "The model accepts both numpy arrays and cuDF dataframes. In order to convert your dataset to cudf format please read the cudf documentation on https://docs.rapids.ai/api/cudf/stable. \n",
    "\n",
    "For additional information on the forest inference library please refer to the documentation on https://docs.rapids.ai/api/cuml/stable/api.html#forest-inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "import os\n",
    "\n",
    "from cuml.test.utils import array_equal\n",
    "from cuml.common.import_utils import has_xgboost\n",
    "\n",
    "from cuml.datasets import make_classification\n",
    "from cuml.metrics import accuracy_score\n",
    "from cuml.model_selection import train_test_split\n",
    "    \n",
    "from cuml import ForestInference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for xgboost\n",
    "Checks if xgboost is present, if not then it throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_xgboost():\n",
    "    import xgboost as xgb\n",
    "else:\n",
    "    raise ImportError(\"Please install xgboost using the conda package,\"\n",
    "                      \"e.g.: conda install -c conda-forge xgboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic data size\n",
    "n_rows = 10000\n",
    "n_columns = 100\n",
    "n_categories = 2\n",
    "random_state = cupy.random.RandomState(43210)\n",
    "\n",
    "# fraction of data used for model training\n",
    "train_size = 0.8\n",
    "\n",
    "# trained model output filename\n",
    "model_path = 'xgb_2000.model'\n",
    "\n",
    "# num of iterations for which xgboost is trained\n",
    "num_rounds = 2000\n",
    "\n",
    "# maximum tree depth in each training round\n",
    "max_depth = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=n_rows,\n",
    "    n_features=n_columns,\n",
    "    n_informative=int(n_columns/5),\n",
    "    n_classes=n_categories,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# convert the dataset to float32\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "# split the dataset into training and validation splits\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train helper function\n",
    "Defines a simple function that trains the XGBoost model and returns the trained model.\n",
    "\n",
    "For additional information on the xgboost library please refer to the documentation on : \n",
    "https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_model(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    model_path='xgb.model',\n",
    "    num_rounds=100, \n",
    "    max_depth=20\n",
    "):\n",
    "    \n",
    "    # set the xgboost model parameters\n",
    "    params = {\n",
    "        'verbosity': 0, \n",
    "        'eval_metric':'error',\n",
    "        'objective':'binary:logistic',\n",
    "        'max_depth': max_depth,\n",
    "        'tree_method': 'gpu_hist'\n",
    "    }\n",
    "    \n",
    "    # convert training data into DMatrix\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    \n",
    "    # train the xgboost model\n",
    "    trained_model = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "    # save the trained xgboost model\n",
    "    trained_model.save_model(model_path)\n",
    "\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict helper function\n",
    "Uses the trained xgboost model to perform prediction and return the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_xgboost_model(X_validation, y_validation, xgb_model):\n",
    "\n",
    "    # predict using the xgboost model\n",
    "    dvalidation = xgb.DMatrix(X_validation, label=y_validation)\n",
    "    predictions = xgb_model.predict(dvalidation)\n",
    "\n",
    "    # convert the predicted values from xgboost into class labels\n",
    "    predictions = cupy.around(predictions)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Predict the model\n",
    "Invoke the function to train the model and get predictions so that we can validate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.58 s, sys: 204 ms, total: 7.78 s\n",
      "Wall time: 7.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train the xgboost model\n",
    "xgboost_model = train_xgboost_model(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    model_path,\n",
    "    num_rounds,\n",
    "    max_depth\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 ms, sys: 0 ns, total: 16.7 ms\n",
      "Wall time: 16.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test the xgboost model\n",
    "trained_model_preds = predict_xgboost_model(\n",
    "    X_validation,\n",
    "    y_validation,\n",
    "    xgboost_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
